[
  {
    "ID": "5.0-0001",
    "Submitter": "MLCommons",
    "Availability": "available",
    "Category": "open",
    "Suite": "datacenter",
    "System": "gh_action",
    "Platform": "gh_action-reference-cpu-pytorch_v2.6.0-default_config",
    "UsedModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Scenario": "Offline",
    "Accuracy": "ROUGE1: 61.7021  ROUGE2: 37.9679  ROUGEL: 39.3617  TOKENS_PER_SAMPLE: 610.0",
    "Nodes": 1,
    "Processor": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "host_processor_core_count": 24,
    "Accelerator": "",
    "a#": "",
    "Location": "open/MLCommons/results/gh_action-reference-cpu-pytorch_v2.6.0-default_config/llama2-70b-99/offline",
    "Software": "pytorch v2.6.0",
    "operating_system": "Ubuntu 22.04 (linux-6.8.0-52-generic-glibc2.35)",
    "Notes": "",
    "compliance": 1,
    "errors": 0,
    "version": "v5.0",
    "inferred": 0,
    "has_power": false,
    "weight_data_types": "fp32",
    "p#": 1,
    "Details": "https://github.com/mlcommons/mlperf_inference_test_submissions_v5.0/tree/main/open/MLCommons/results/gh_action-reference-cpu-pytorch_v2.6.0-default_config",
    "Code": "https://github.com/mlcommons/mlperf_inference_test_submissions_v5.0/tree/main/open/MLCommons/code",
    "Unique ID (e.g. for Audit)": "datacenter/open/MLCommons/gh_action-reference-cpu-pytorch_v2.6.0-default_config/llama2-70b-99",
    "ColorKey": "availableMLCommons",
    "Performance_Result": 0.40413,
    "Performance_Units": "Tokens/s"
  }
]