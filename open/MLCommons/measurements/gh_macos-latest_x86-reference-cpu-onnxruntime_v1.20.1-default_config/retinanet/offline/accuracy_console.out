python3 python/main.py --profile retinanet-onnxruntime --model "/Users/runner/MLC/repos/local/cache/download-file_22cbbe32/resnext50_32x4d_fpn.onnx" --dataset-path /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6 --output "/Users/runner/MLC/repos/local/cache/get-mlperf-inference-results-dir_2048ed32/test_results/gh_macos-latest_x86-reference-cpu-onnxruntime-v1.20.1-default_config/retinanet/offline/accuracy" --scenario Offline --max-batchsize 1 --count 5 --threads 3 --user_conf /Users/runner/MLC/repos/mlcommons@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/cf0ad6a2bea4480f87352ae18021a64d.conf --accuracy --use_preprocessed_dataset --cache_dir /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6 --dataset-list /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6/annotations/openimages-mlperf.json
INFO:main:Namespace(dataset='openimages-800-retinanet-onnx', dataset_path='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6', dataset_list='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6/annotations/openimages-mlperf.json', data_format=None, profile='retinanet-onnxruntime', scenario='Offline', max_batchsize=1, model='/Users/runner/MLC/repos/local/cache/download-file_22cbbe32/resnext50_32x4d_fpn.onnx', output='/Users/runner/MLC/repos/local/cache/get-mlperf-inference-results-dir_2048ed32/test_results/gh_macos-latest_x86-reference-cpu-onnxruntime-v1.20.1-default_config/retinanet/offline/accuracy', inputs=['images'], outputs=['boxes', 'labels', 'scores'], backend='onnxruntime', device=None, model_name='retinanet', threads=3, qps=None, cache=0, cache_dir='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b1ee38c6', preprocessed_dir=None, use_preprocessed_dataset=True, accuracy=True, find_peak_performance=False, debug=False, user_conf='/Users/runner/MLC/repos/mlcommons@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/cf0ad6a2bea4480f87352ae18021a64d.conf', audit_conf='audit.config', time=None, count=5, performance_sample_count=None, max_latency=None, samples_per_query=8)
INFO:coco:loaded 5 images, cache=0, already_preprocessed=True, took=0.0sec
INFO:main:starting TestScenario.Offline
loading annotations into memory...
Done (t=0.00s)
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(756, 7)
0/756
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.07s).
Accumulating evaluation results...
DONE (t=0.06s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.824
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.831
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.875
TestScenario.Offline qps=0.45, mean=7.6508, time=11.099, acc=42.328%, mAP=76.951%, queries=5, tiles=50.0:5.8333,80.0:10.4802,90.0:10.6202,95.0:10.6902,99.0:10.7462,99.9:10.7588
