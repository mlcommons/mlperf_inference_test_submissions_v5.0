python3 python/main.py --profile retinanet-onnxruntime --model "/Users/runner/MLC/repos/local/cache/download-file_a1e9f8a0/resnext50_32x4d_fpn.onnx" --dataset-path /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788 --output "/Users/runner/MLC/repos/local/cache/get-mlperf-inference-results-dir_3501fc41/test_results/gh_macos-latest_x86-reference-cpu-onnxruntime-v1.20.1-default_config/retinanet/offline/accuracy" --scenario Offline --max-batchsize 1 --count 5 --threads 3 --user_conf /Users/runner/MLC/repos/GATEOverflow@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/7b1087aacc9f44f49ccdf93f5a18b20a.conf --accuracy --use_preprocessed_dataset --cache_dir /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788 --dataset-list /Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788/annotations/openimages-mlperf.json
INFO:main:Namespace(dataset='openimages-800-retinanet-onnx', dataset_path='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788', dataset_list='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788/annotations/openimages-mlperf.json', data_format=None, profile='retinanet-onnxruntime', scenario='Offline', max_batchsize=1, model='/Users/runner/MLC/repos/local/cache/download-file_a1e9f8a0/resnext50_32x4d_fpn.onnx', output='/Users/runner/MLC/repos/local/cache/get-mlperf-inference-results-dir_3501fc41/test_results/gh_macos-latest_x86-reference-cpu-onnxruntime-v1.20.1-default_config/retinanet/offline/accuracy', inputs=['images'], outputs=['boxes', 'labels', 'scores'], backend='onnxruntime', device=None, model_name='retinanet', threads=3, qps=None, cache=0, cache_dir='/Users/runner/MLC/repos/local/cache/get-preprocessed-dataset-openimages_b47f3788', preprocessed_dir=None, use_preprocessed_dataset=True, accuracy=True, find_peak_performance=False, debug=False, user_conf='/Users/runner/MLC/repos/GATEOverflow@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/7b1087aacc9f44f49ccdf93f5a18b20a.conf', audit_conf='audit.config', time=None, count=5, performance_sample_count=None, max_latency=None, samples_per_query=8)
INFO:coco:loaded 5 images, cache=0, already_preprocessed=True, took=0.0sec
INFO:main:starting TestScenario.Offline
loading annotations into memory...
Done (t=0.00s)
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(756, 7)
0/756
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.04s).
Accumulating evaluation results...
DONE (t=0.08s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.824
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.831
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.875
TestScenario.Offline qps=0.44, mean=8.0084, time=11.470, acc=42.328%, mAP=76.951%, queries=5, tiles=50.0:6.1474,80.0:10.9816,90.0:11.0569,95.0:11.0946,99.0:11.1247,99.9:11.1314
